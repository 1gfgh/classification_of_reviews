### Отчёт по эксперименту: оценка качества RuBERT для классификации отзывов Lamoda

#### 1. Zero-shot оценка (без дообучения)
- **Accuracy**: 0.202
- **Распределение предсказаний**:
  - ★: 117
  - ★★: 0 (не предсказан ни один случай)
  - ★★★: 1089
  - ★★★★: 0 (не предсказан ни один случай)
  - ★★★★★: 3794
- **Основные проблемы**:
  - Критический перекос в сторону класса ★★★★★ (76.5% recall)
  - Классы ★★ и ★★★★ полностью игнорируются моделью
  - Низкий F1-score (0.115 macro avg)

#### 2. Результаты после Fine-tuning
- **Обучение**:
  - 4000 сбалансированных примеров (5 классов × 1000)
  - 2 эпохи, batch size = 4
  - Final train loss: 1.284
- **Качество на тестовой выборке** (1000 примеров):
  - **Accuracy**: 0.453
  - **F1-score (weighted)**: 0.458
  - **Детализация по классам**:
    | Класс | Precision | Recall | F1-score |
    |-------|-----------|--------|----------|
    | ★     | 0.522     | 0.465  | 0.492    |
    | ★★    | 0.354     | 0.280  | 0.313    |
    | ★★★   | 0.299     | 0.415  | 0.347    |
    | ★★★★  | 0.415     | 0.440  | 0.427    |
    | ★★★★★ | 0.764     | 0.665  | 0.711    |

#### 3. Выводы
1. **Zero-shot подход неэффективен** для задачи:
   - Модель демонстрирует сильное смещение к положительным оценкам
   - Неспособность различать критические классы (★★ и ★★★★)

2. **Fine-tuning существенно улучшает качество**:
   + Увеличение accuracy в 2.24 раза
   + Появление различимости всех классов
   + Наилучшее качество на крайних классах (★ и ★★★★★)

3. **Проблемные зоны**:
   - Низкое качество на нейтральных/смешанных оценках (★★-★★★)
   - Дисбаланс между precision и recall в классе ★★★

#### PPS

- Было очень тяжело провести это обучение из-за нехватки мощности наших устройств, любой запуск с хорошим числом эпох прогнозировал от 3х дней работы ноутбука + он страшно зависал. Понимаем, что результаты не самые лучшие но это все на что хватило процессора и вдеокарты.