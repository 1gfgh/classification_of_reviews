Отчёт по обучению модели RuBERT на задаче бинарной классификации отзывов

1. Общая информация

Модель cointegrated/rubert-tiny была дообучена на задаче бинарной классификации отзывов:
	•	Метка 1 (“да”) — если рейтинг ≥ 4
	•	Метка 0 (“нет”) — если рейтинг ≤ 3

Обучение проводилось на сбалансированной выборке с сохранением 20 000 примеров с оценкой 5 и всех остальных отзывов. Модель обучалась 3 эпохи.

⸻

2. Финальные метрики на тесте

Метрика	Значение
eval_loss	0.2750
eval_accuracy	88.74%
eval_f1	0.9329
eval_runtime	17.37 сек
samples/sec	382.02
steps/sec	23.89
эпоха	3


⸻

3. Классификационный отчёт (на тестовой выборке)

Класс	Precision	Recall	F1-score	Support
нет (0)	0.69	0.62	0.65	1126
да (1)	0.92	0.94	0.93	5511

Общие метрики:
	•	Accuracy: 88.7%
	•	Macro avg F1: 0.79
	•	Weighted avg F1: 0.88

⸻

4. Выводы
	•	Модель показывает высокое качество на положительном классе (“да”), с precision = 0.92 и recall = 0.94.
	•	На отрицательном классе (“нет”) показатели ниже: precision = 0.69, recall = 0.62, что снижает macro average F1 до 0.79.
	•	Итоговая точность модели составляет 88.7%, что указывает на хорошее обобщение.
	•	Небольшой дисбаланс классов (1126 против 5511) влияет на метрики отрицательного класса.
	•	Для дальнейшего улучшения можно рассмотреть:
	•	переусиление отрицательного класса (oversampling)
	•	использование более сложных моделей (например, DeepPavlov/rubert-base-cased)
	•	настройку гиперпараметров (learning rate, batch size)
