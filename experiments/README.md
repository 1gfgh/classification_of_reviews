# Описание экспериментов
Кратко рассмотрим, какие эксперименты мы провели, а также каких результатов добились. Конкретные цифры и подробное описание экспериментов вы сможете посмотреть в соответствующих разделах.
## Feature engineering
Мы [попробовали](feature_engineering/feature_engineering_experiments.ipynb) вынести отдельные эмодзи(наличие и их количество), как отдельные признаки, а после обучить бейзлайн на них на основе датасета WildBerries. Прирост оказался минимальным, так что было решено исследовать более перспективные подходы. 
## Finetuning
На основе языковой модели RU-BERT, мы решили [посмотреть](fine-tuning/finetune.ipynb) в сторону дообучения для задачи классификации отзывов по количеству звёзд от 1 до 5. Предобученная модель в режиме ZeroShot показала крайне низкие метрики. После было проведено дообучение на датасете Lamoda и подбор оптимальных гиперпараметров для предсказания по пяти классам. Самые плохие и хорошие отзывы классифицировались довольно точно, однако промежуточные модель определяла печально. Отдельной проблемой были недостаточные вычислительные мощности, что ощутимо ограничивало возможности. Вы также можете изучить [более подробный отчет.](fine-tuning/finetune_report.md)
## Trees and ensemble
Был [проведен ряд экспериментов](trees/trees.ipynb), посмотрим кратко на каждый.

* DecisionTree и RandomForest не превзошли baseline: DecisionTree ухудшил метрики, а RandomForest улучшил precision для негативных отзывов, но снизил recall.

* CatBoost тестировался в разных конфигурациях:

    * Без тонкой настройки показал близкие к baseline результаты.

    * На 10% данных с подбором гиперпараметров метрики ухудшились.

    * С эмбеддингами RuBERT-tiny2 результаты оказались ещё ниже.

* Ансамбли моделей дали лучший эффект:

    * Комбинация CatBoost и baseline улучшила F1 для негативных отзывов.

    * Добавление вероятности от baseline в CatBoost как признака дало схожий результат при меньшем весе модели.

Подробно изучить эксперименты можно [тут.](trees/trees.md)

## Общий вывод
Ансамблирование с добавлением нового признака дало наилучший результат.