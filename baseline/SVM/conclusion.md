# Итоги экспериментов 
Подробные цифры вы можете посмотреть в соответсвующих файлах. В файле [SVM](SVM.ipynb) расширенный вариант экспериментов на основе датасета WildBerries. Лучшие варианты были отобраны и на них протестированы остальные датасеты.

## Пару слов о том, что было

Как вариант бейзлайна мы рассмотрели SVM. Стоп-слова не удалялись. Стеммизация и минимальная предобработка текста была проведена сразу. Векторизация текста была произведена по средствам tf-idf с n-граммами от 1 до 3. Для начала мы рассмотрели самый базовый вариант с линейным ядром и C = 1. После решено было проверить улучшит ли результат, если обучать на трех векторах(название, описание, текст отзыва), вместо одного(только текст отзыва). Данный способ работал ожидаемо кратно больше, однако не принес желаемых улучшений, поэтому вернулись к варианту на одном векторе. Далее было решено посмотреть на результаты иного ядра - rbf. Параллельно проверяли, как сильно повлияет на результат изменение параметра C. 

Лучшими результатами оказался самый первый и наивный вариант - linear kernel, C = 1. Схожие результаты показали модели с rbf kernel, C = {1, 10}. На этих трех вариантах и были протестированы остальные датасеты.

Схожие результаты показала и логистическая регрессия, которая легче интерпретируется, работает быстрее, а также является более "явным и очевидным" подходом к задачи бинарной классификации, чем построение разделяющей гиперплоскости. В связи со всем вышесказанным, было решено оставить логистическую регрессию, как основной бейзлайн.